{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32458089",
   "metadata": {},
   "source": [
    "# 导包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b9ca90fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8269d05650>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import math\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6344a47d",
   "metadata": {},
   "source": [
    "# positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "07d6a3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,d_model,max_len=5000):\n",
    "        super(PositionalEncoding,self).__init__()\n",
    "        pe=torch.zeros(max_len,d_model)\n",
    "        position=torch.arange(0,max_len,dtype=torch.float).unsqueeze(1)\n",
    "        div_term=torch.exp(torch.arange(0,d_model,2).float()*(-math.log(10000)/d_model))\n",
    "\n",
    "        pe[:,0::2]=torch.sin(position*div_term)\n",
    "        pe[:,1::2]=torch.cos(position*div_term)\n",
    "\n",
    "        pe=pe.unsqueeze(0)\n",
    "        self.register_buffer('pe',pe)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=x+self.pe[:,:x.size(1),:]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8dbc62",
   "metadata": {},
   "source": [
    "# Scaled Dot-Product Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "85059ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self,dropout=0.1):\n",
    "        super(ScaledDotProductAttention,self).__init__()\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,query,key,value,mask=None):\n",
    "        d_k=query.size(-1)\n",
    "        scores=torch.matmul(query,key.transpose(-2,-1))/math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None:\n",
    "            scores=scores.masked_fill(mask==0,-1e9)\n",
    "\n",
    "        attn_weights=torch.softmax(scores,dim=-1)\n",
    "        attn_weights=self.dropout(attn_weights)\n",
    "        output=torch.matmul(attn_weights,value)\n",
    "\n",
    "        return output,attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df993bd",
   "metadata": {},
   "source": [
    "# Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a83a297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,d_model,n_heads,dropout=0.1):\n",
    "        super(MultiHeadAttention,self).__init__()\n",
    "        assert d_model%n_heads==0,\"d_model必须能被n_heads整除\"\n",
    "\n",
    "        self.d_model=d_model\n",
    "        self.n_heads=n_heads\n",
    "        self.d_k=d_model//n_heads\n",
    "\n",
    "        self.w_q=nn.Linear(d_model,d_model)\n",
    "        self.w_k=nn.Linear(d_model,d_model)\n",
    "        self.w_v=nn.Linear(d_model,d_model)\n",
    "        self.w_o=nn.Linear(d_model,d_model)\n",
    "\n",
    "        self.attention=ScaledDotProductAttention(dropout)\n",
    "\n",
    "    def forward(self,query,key,value,mask=None):\n",
    "        batch_size=query.size(0)\n",
    "\n",
    "        Q=self.w_q(query).view(batch_size,-1,self.n_heads,self.d_k).transpose(1,2)\n",
    "        K=self.w_k(key).view(batch_size,-1,self.n_heads,self.d_k).transpose(1,2)\n",
    "        V=self.w_v(value).view(batch_size,-1,self.n_heads,self.d_k).transpose(1,2)\n",
    "\n",
    "        attn_output,attn_weights=self.attention(Q,K,V,mask)\n",
    "\n",
    "        attn_output=attn_output.transpose(1,2).contiguous().view(batch_size,-1,self.d_model)\n",
    "        output=self.w_o(attn_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcb6793",
   "metadata": {},
   "source": [
    "# Position-wise Feed-Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2dbdcfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseForward(nn.Module):\n",
    "    def __init__(self,d_model,d_ff,dropout=0.1):\n",
    "        super(PositionwiseForward,self).__init__()\n",
    "        self.linear1=nn.Linear(d_model,d_ff)\n",
    "        self.linear2=nn.Linear(d_ff,d_model)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        self.relu=nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.linear2(self.dropout(self.relu(self.linear1(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72abaf1",
   "metadata": {},
   "source": [
    "# Encoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "486151ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self,d_model,n_heads,d_ff,dropout=0.1):\n",
    "        super(EncoderLayer,self).__init__()\n",
    "        self.self_attn=MultiHeadAttention(d_model,n_heads,dropout)\n",
    "        self.feed_forward=PositionwiseForward(d_model,d_ff,dropout)\n",
    "        self.norm1=nn.LayerNorm(d_model)\n",
    "        self.norm2=nn.LayerNorm(d_model)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x,mask=None):\n",
    "        attn_output=self.self_attn(x,x,x,mask)\n",
    "        x=self.norm1(x+self.dropout(attn_output))\n",
    "\n",
    "        ff_output=self.feed_forward(x)\n",
    "        x=self.norm2(x+self.dropout(ff_output))\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7c619c",
   "metadata": {},
   "source": [
    "# Decoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c8b477c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self,d_model,n_heads,d_ff,dropout=0.1):\n",
    "        super(DecoderLayer,self).__init__()\n",
    "        self.self_attn=MultiHeadAttention(d_model,n_heads,dropout)\n",
    "        self.cross_attn=MultiHeadAttention(d_model,n_heads,dropout)\n",
    "        self.feed_forward=PositionwiseForward(d_model,d_ff,dropout)\n",
    "        self.norm1=nn.LayerNorm(d_model)\n",
    "        self.norm2=nn.LayerNorm(d_model)\n",
    "        self.norm3=nn.LayerNorm(d_model)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x,enc_output,src_mask,tgt_mask):\n",
    "        attn_output=self.self_attn(x,x,x,tgt_mask)\n",
    "        x=self.norm1(x+self.dropout(attn_output))\n",
    "\n",
    "        attn_output=self.cross_attn(x,enc_output,enc_output,src_mask)\n",
    "        x=self.norm2(x+self.dropout(attn_output))\n",
    "\n",
    "        ff_output=self.feed_forward(x)\n",
    "        x=self.norm3(x+self.dropout(ff_output))\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f02d251",
   "metadata": {},
   "source": [
    "# 编码器&解码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dbcf7034",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,vocab_size,d_model,n_layers,n_heads,d_ff,max_len,dropout=0.1):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.d_model=d_model\n",
    "        self.embedding=nn.Embedding(vocab_size,d_model)\n",
    "        self.pos_encoding=PositionalEncoding(d_model,max_len)\n",
    "        self.layers=nn.ModuleList(\n",
    "            [EncoderLayer(d_model,n_heads,d_ff,dropout)for _ in range(n_layers)]\n",
    "        )\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x,mask):\n",
    "        x=self.embedding(x)*math.sqrt(self.d_model)\n",
    "        x=self.pos_encoding(x)\n",
    "        x=self.dropout(x)\n",
    "        for layer in self.layers:\n",
    "            x=layer(x,mask)\n",
    "        return x \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, n_layers, n_heads, d_ff, max_len, dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
    "        self.layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, memory, tgt_mask=None, memory_mask=None):\n",
    "        # x: [batch_size, tgt_seq_len]\n",
    "        # memory: [batch_size, src_seq_len, d_model]\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)  # scale embedding\n",
    "        x = self.pos_encoding(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, tgt_mask, memory_mask)\n",
    "\n",
    "        return x  # [batch_size, tgt_seq_len, d_model]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a7cc23",
   "metadata": {},
   "source": [
    "# 完整的Transformer模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "61c7d382",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self,src_voacb_size,tgt_vocab_size,d_model,n_layers,n_heads,d_ff,max_len,dropout=0.1):\n",
    "        super(Transformer,self).__init__()\n",
    "        self.encoder=Encoder(src_voacb_size,d_model,n_layers,n_heads,d_ff,max_len,dropout)\n",
    "        self.decoder=Decoder(tgt_vocab_size,d_model,n_layers,n_heads,d_ff,max_len,dropout)\n",
    "        self.liner=nn.Linear(d_model,tgt_vocab_size)\n",
    "\n",
    "    def forward(self,src,tgt,src_mask,tgt_mask):\n",
    "        enc_output=self.encoder(src,src_mask)\n",
    "        dec_output=self.decoder(tgt,enc_output,src_mask,tgt_mask)\n",
    "        output=self.liner(dec_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b59c968",
   "metadata": {},
   "source": [
    "# 掩码的生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0a6b9844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(src, tgt, pad_idx):\n",
    "    # 源序列填充掩码 [batch_size, 1, 1, src_len]\n",
    "    src_mask = (src != pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "    \n",
    "    # 目标序列填充掩码 [batch_size, 1, tgt_len, 1]\n",
    "    tgt_pad_mask = (tgt != pad_idx).unsqueeze(1).unsqueeze(3)\n",
    "    \n",
    "    # 目标序列子序列掩码 [1, tgt_len, tgt_len]\n",
    "    tgt_len = tgt.size(1)\n",
    "    tgt_sub_mask = torch.tril(torch.ones((tgt_len, tgt_len), device=tgt.device)).bool()\n",
    "    tgt_sub_mask = tgt_sub_mask.unsqueeze(0)\n",
    "    \n",
    "    # 组合目标序列掩码 [batch_size, 1, tgt_len, tgt_len]\n",
    "    tgt_mask = tgt_pad_mask & tgt_sub_mask\n",
    "    \n",
    "    return src_mask, tgt_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc272b1",
   "metadata": {},
   "source": [
    "# 数据处理与训练流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b82fa9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transformer(model,dataloder,optimizer,criterion,pad_idx,device,n_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss=0\n",
    "        for batch_idx,(src,tgt) in enumerate(dataloder):\n",
    "            src,tgt=src.to(device),tgt.to(device)\n",
    "            src_mask,tgt_mask=create_mask(src,tgt,pad_idx)\n",
    "            src_mask,tgt_mask=src_mask.to(device),tgt_mask.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(src, tgt[:, :-1], src_mask, tgt_mask)\n",
    "\n",
    "\n",
    "            loss=criterion(\n",
    "                output.contiguous().view(-1,output.size(-1)),\n",
    "                tgt[:,1:].contiguous().view(-1)\n",
    "            )\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss+=loss.item()\n",
    "\n",
    "    avg_loss=total_loss/len(dataloder)\n",
    "    print(f'Epoch{epoch+1}/{n_epochs},Average Loss:{avg_loss:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmrec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
